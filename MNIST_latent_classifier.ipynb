{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set(rc={\"figure.figsize\":(7, 7)}) #width=3, #height=4\n",
    "\n",
    "import threading\n",
    "import os\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./wandb_export.csv\")\n",
    "df = df.drop(index=8) # remove duplicate of restart\n",
    "\n",
    "df_train = df[df[\"Name\"].str.startswith(\"Traning\")]\n",
    "\n",
    "summary = pd.DataFrame(columns=[\"ID\",\"Loss\", \"Warmup\",\"Psudoinputs\",\"S\", \"Orgmis\",\"Seed\",\"MaxEpochs\"])\n",
    "\n",
    "\n",
    "for d in df_train[\"Name\"].str.split(\" \"):\n",
    "    id = d[1].split(\"-\")[0]\n",
    "    \n",
    "    test_ = df[df[\"Name\"].str.startswith(\"Testing \"+str(id))]\n",
    "    train_ = df[df[\"Name\"].str.startswith(\"Traning \"+str(id))]\n",
    "        \n",
    "    summary_data = {\n",
    "        \"ID\":[str(id)],\n",
    "        \"Loss\":test_[\"mean(loss)\"].values,\n",
    "        \"Warmup\":train_[\"Warmup epochs\"].values,\n",
    "        \"Psudoinputs\":train_[\"lambda (psudosamples)\"].values,\n",
    "        \"S\":train_[\"S (encoders)\"].values,\n",
    "        \"Orgmis\":train_[\"Original miselbo (old)\"].values,\n",
    "        \"Seed\":train_[\"Seed\"].values,\n",
    "        \"MaxEpochs\":train_[\"Max epochs\"].values,\n",
    "    }\n",
    "        \n",
    "    summary = summary.append(pd.DataFrame(summary_data))\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORE_MODELS = \"./path/STORE_MODELS\"\n",
    "def load_parameters(model_id, STORE_MODELS=STORE_MODELS, data_type=\"test\"):\n",
    "    if data_type == \"test\":\n",
    "        z_mean = pd.read_csv(\"%s/%s_latent/test_z_mean.csv\" % (STORE_MODELS, model_id))\n",
    "        z_std = pd.read_csv(\"%s/%s_latent/test_z_std.csv\" % (STORE_MODELS, model_id))\n",
    "        label = pd.read_csv(\"%s/%s_latent/test_label.csv\" % (STORE_MODELS, model_id))\n",
    "    \n",
    "    elif data_type == \"train\":\n",
    "        z_mean = pd.read_csv(\"%s/%s_latent/train_z_mean.csv\" % (STORE_MODELS, model_id))\n",
    "        z_std = pd.read_csv(\"%s/%s_latent/train_z_std.csv\" % (STORE_MODELS, model_id))\n",
    "        label = pd.read_csv(\"%s/%s_latent/train_label.csv\" % (STORE_MODELS, model_id))\n",
    "    \n",
    "    return label, z_mean, z_std\n",
    "\n",
    "\n",
    "label, z_mean, z_std = load_parameters(\"example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metrics(model_id, STORE_MODELS=STORE_MODELS):\n",
    "    \n",
    "    files = os.listdir(\"%s/%s_test/\" % (STORE_MODELS, model_id))\n",
    "    S = sum(map(lambda x: x.startswith(\"test\") , files))-2\n",
    "    \n",
    "    df = pd.read_csv(\"%s/%s_test/test_qjsd.csv\" % (STORE_MODELS, model_id))\n",
    "    df = df.rename(columns={\"x1\":\"qjsd\"})\n",
    "    \n",
    "    df[\"loss\"] = pd.read_csv(\"%s/%s_test/test_loss.csv\" % (STORE_MODELS, model_id)).values.T\n",
    "    \n",
    "    for s in range(S):\n",
    "         df[\"kl_\" + str(s+1)] = pd.read_csv(\"%s/%s_test/test_KL_q%i.csv\" % (STORE_MODELS, model_id, s+1)).values\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_metrics(df):\n",
    "    fig, axs = plt.subplots(ncols=3, nrows=1)\n",
    "    axs[0].boxplot(df[\"qjsd\"], labels=[\"qjsd\"])\n",
    "    axs[1].boxplot(df[\"loss\"], labels=[\"loss\"])\n",
    "    axs[2].boxplot(df.drop([\"qjsd\", \"loss\"], axis=1))\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "df  = load_metrics(\"example\")\n",
    "plot_metrics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(mean, std, k=1):\n",
    "    n, f = mean.shape\n",
    "    out = [mean + np.random.rand(n,f) * std for i in range(k)]\n",
    "    out = np.concatenate(out, axis=1)\n",
    "    return out\n",
    "\n",
    "#data = sample(z_mean.values, z_std.values, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TSNE_embedding(data,n_components=2):\n",
    "    out = TSNE(n_components=n_components).fit_transform(data)\n",
    "    return out \n",
    "\n",
    "#data_embedding = get_TSNE_embedding(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_embedding(data, label, title=\"\"):\n",
    "    df = pd.DataFrame(data, columns=[\"x1\", \"x2\"])\n",
    "    df[\"label\"] = label\n",
    "    sns.scatterplot(x='x1', y='x2', data=df, hue='label', alpha=0.2)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "#scatter_embedding(data_embedding,label.values, title=\"example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca_embedding(data,n_components=2):\n",
    "    out = PCA(n_components=n_components).fit_transform(data)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\n",
    "    \"Nearest Neighbors\":[],\n",
    "    \"Linear SVM\":[],\n",
    "    #\"RBF SVM\":[],\n",
    "    #\"Gaussian Process\":[],\n",
    "    #\"Decision Tree\":[],\n",
    "    #\"Random Forest\":[],\n",
    "    \"Neural Net\":[],\n",
    "    #\"AdaBoost\":[],\n",
    "    #\"Naive Bayes\":[],\n",
    "    \"QDA\":[],\n",
    "}\n",
    "\n",
    "classifier = [\n",
    "    KNeighborsClassifier(),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    #SVC(gamma=2, C=1),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    #DecisionTreeClassifier(max_depth=5),\n",
    "    #RandomForestClassifier(),\n",
    "    MLPClassifier(max_iter=2000),\n",
    "    #AdaBoostClassifier(),\n",
    "    #GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]\n",
    "\n",
    "\n",
    "def classification_models(model_id, k=0, names=names, classifier=classifier):\n",
    "    h = 0.02 \n",
    "\n",
    "    train_label, train_z_mean, train_z_std = load_parameters(model_id, data_type=\"train\")\n",
    "    test_label, test_z_mean, test_z_std = load_parameters(model_id, data_type=\"test\")\n",
    "\n",
    "    if k > 0:\n",
    "        x_train = sample(train_z_mean.values, train_z_std.values, k=k)\n",
    "        x_test = sample(test_z_mean.values, test_z_std.values, k=k)\n",
    "    else: \n",
    "        x_train = np.concatenate([train_z_mean, train_z_std], axis=1)\n",
    "        x_test = np.concatenate([test_z_mean, test_z_std], axis=1)\n",
    "\n",
    "    y_train = train_label.values.ravel()\n",
    "    y_test = test_label.values.ravel()\n",
    "\n",
    "\n",
    "    def fitting_testing(name, clf, x_test, y_test, x_train, y_train):\n",
    "        clf.fit(x_train, y_train)\n",
    "        score = clf.score(x_test, y_test)\n",
    "        print(\"%s: %.10f\"% (name,score))\n",
    "        return score\n",
    "\n",
    "    \n",
    "    for name, clf in zip(names.keys(),  classifier):\n",
    "        score = fitting_testing(name,clf,x_test,y_test,x_train,y_train)\n",
    "        names[name].append(score)\n",
    "        \n",
    "    \n",
    "\n",
    "for id in summary[\"ID\"]:\n",
    "    classification_models(id, k=0)\n",
    "\n",
    "for name in names.keys():\n",
    "    summary[\"Classification \" + name] = names[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add metricsv to df\n",
    "df_metric = load_metrics(\"example\")\n",
    "df_metric.columns\n",
    "\n",
    "qjsd = []\n",
    "kls = [] \n",
    "\n",
    "for id in summary[\"ID\"]:\n",
    "    df_metric = load_metrics(id)\n",
    "    \n",
    "    qjsd.append(np.mean(df_metric[\"qjsd\"]))\n",
    "    kls.append(np.mean(df_metric.drop(columns=[\"qjsd\", \"loss\"]).values))\n",
    "\n",
    "summary[\"mean(qjsd)\"] = qjsd\n",
    "summary[\"mean(kl_all)\"] = kls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv(\"analytics.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
